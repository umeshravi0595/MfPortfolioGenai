{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54cc1677-b60a-44ea-9857-349d0ab7b7c2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 1"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install databricks-vectorsearch\n",
    "# %pip install --upgrade databricks-langchain langchain-community langchain databricks-sql-connector\n",
    "# dbutils.library.restartPython()\n",
    "# %pip install -U mlflow\n",
    "# dbutils.library.restartPython()\n",
    "# %pip install databricks-sql-connector pandas\n",
    "# dbutils.library.restartPython()\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from databricks.vector_search.client import VectorSearchClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f05b0af-e6a9-4f6e-953f-51c22e89f04b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "# w.secrets.create_scope(\n",
    "#     scope=\"pizza-secrets\"\n",
    "# )\n",
    "# Now you can add your secret as before\n",
    "w.secrets.put_secret(\n",
    "    scope=\"pizza-secrets\",\n",
    "    key=\"DATABRICKS_TOKEN\",\n",
    "    string_value=dbutils.notebook.entry_point\n",
    "        .getDbutils()\n",
    "        .notebook()\n",
    "        .getContext()\n",
    "        .apiToken()\n",
    "        .get()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ff50e94-9b72-42c7-b735-0fb9dd938e0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ctx = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
    "\n",
    "os.environ[\"DATABRICKS_HOST\"] = ctx.apiUrl().get()\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = ctx.apiToken().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "304875b3-9ffe-44c6-aa67-a5200dca2f05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from databricks import sql\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "\n",
    "# def run_sql_warehouse_query(query: str) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Executes a SQL query against Databricks SQL Warehouse\n",
    "#     and returns a Pandas DataFrame.\n",
    "#     \"\"\"\n",
    "\n",
    "#     with sql.connect(\n",
    "#         server_hostname=\"dbc-741c7540-6155.cloud.databricks.com\",\n",
    "#         http_path=\"/sql/1.0/warehouses/e2eb5bcf69add002\",\n",
    "#         access_token=os.environ[\"DATABRICKS_TOKEN\"],\n",
    "#     ) as connection:\n",
    "#         return pd.read_sql(query, connection)\n",
    "    \n",
    "# df = run_sql_warehouse_query(\"select * from retail_analytics.pizza.gold_pizza_metrics_daily\")\n",
    "\n",
    "# # Convert for MLflow output safety\n",
    "# result_json = df.to_json(orient=\"records\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d221f6d6-b061-4bdd-bacf-7b3ffa693966",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "model with orchestration for sql route"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import mlflow.pyfunc\n",
    "# import os\n",
    "# from openai import OpenAI\n",
    "# from databricks_langchain import DatabricksVectorSearch\n",
    "# from databricks import sql\n",
    "\n",
    "\n",
    "# class PizzaRAGPyFuncModel(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # LOAD CONTEXT\n",
    "#     # -----------------------------\n",
    "#     def load_context(self, context):\n",
    "\n",
    "#         self.client = OpenAI(\n",
    "#             base_url=f\"{os.environ['DATABRICKS_HOST']}/serving-endpoints\",\n",
    "#             api_key=os.environ[\"DATABRICKS_TOKEN\"],\n",
    "#         )\n",
    "\n",
    "#         # Vector Search (ONLY semantic tables)\n",
    "#         self.ingredient_summary_vs = DatabricksVectorSearch(\n",
    "#             index_name=\"retail_analytics.pizza.gold_semantic_ingredient_summary_index\",\n",
    "#             endpoint=\"pizza-rag-endpoint\",\n",
    "#         )\n",
    "\n",
    "#         self.pizza_vs = DatabricksVectorSearch(\n",
    "#             index_name=\"retail_analytics.pizza.gold_semantic_pizza_index\",\n",
    "#             endpoint=\"pizza-rag-endpoint\",\n",
    "#         )\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # INTENT DETECTION\n",
    "#     # -----------------------------\n",
    "#     def detect_query_intent(self, question: str) -> str:\n",
    "#         q = question.lower()\n",
    "\n",
    "#         if any(k in q for k in [\n",
    "#             \"how many\", \"how much\", \"total\", \"sum\",\"analyse\"\n",
    "#             \"count\", \"sold\", \"revenue\", \"income\",\n",
    "#             \"most\", \"highest\", \"top\", \"maximum\",\n",
    "#             \"month\", \"year\", \"january\", \"february\",\n",
    "#             \"march\", \"april\", \"may\", \"june\", \"july\",\n",
    "#             \"august\", \"september\", \"october\", \"november\", \"december\",\"sales\"\n",
    "#         ]):\n",
    "#             return \"SQL_ANALYTICS\"\n",
    "\n",
    "#         if any(k in q for k in [\n",
    "#             \"ingredient\", \"ingredients\", \"what is used\",\n",
    "#             \"what does\", \"describe\", \"explain\"\n",
    "#         ]):\n",
    "#             return \"SEMANTIC\"\n",
    "\n",
    "#         return \"SEMANTIC\"\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # SQL GENERATION (CONTROLLED)\n",
    "#     # -----------------------------\n",
    "#     def generate_sql(self, question: str) -> str:\n",
    "#         \"\"\"\n",
    "#         LLM-assisted SQL generation over semantic FACT tables\n",
    "#         \"\"\"\n",
    "#         prompt = f\"\"\"\n",
    "# You are a senior data analyst.\n",
    "\n",
    "# You are an expert Databricks Spark SQL engineer generate a Spark SQL query ONLY using the tables below:\n",
    "\n",
    "# 1. retail_analytics.pizza.gold_pizza_metrics_monthly\n",
    "#    columns: pizza_name_id, month, year, total_pizzas_sold, total_revenue\n",
    "# 2. retail_analytics.pizza.gold_ingredient_usage\n",
    "#    columns: pizza_name_id, ingredient, month, year, total_pizza_month,items_qty_in_grams,total_ingredient_grams\n",
    "# 3. retail_analytics.pizza.gold_pizza_metrics_daily\n",
    "#    columns: pizza_name_id, total_pizza_day,day,month, year,revenue_perday\n",
    "# Generate ONLY valid Databricks Spark SQL.\n",
    "# Strict rules:\n",
    "# - The SQL engine is Databricks (Apache Spark SQL), NOT SQL Server, Postgres, or MySQL.\n",
    "# - Never reuse column aliases in the same SELECT.\n",
    "# - if question is on specific date use daily table if it is for year or month use monthly table and use both table if you revenue is needed to be calulated\n",
    "# - if question is on ingredient use ingredient table and if needed for some analysis join all three tables for results\n",
    "# - Use only the provided schema\n",
    "# - Never apply aggregate functions (SUM, AVG, COUNT) to an alias.\n",
    "# - Always aggregate raw columns first.\n",
    "# - All non-aggregated columns must appear in GROUP BY.\n",
    "# - Do NOT use SELECT aliases in ORDER BY if they are derived from aggregates.\n",
    "# - Use explicit column names that exist in the provided schema.\n",
    "# - Do NOT include markdown, comments, or ```sql fences.\n",
    "# - Output ONLY the SQL query.\n",
    "\n",
    "# If the question is ambiguous, choose the safest interpretation that produces valid Spark SQL.\n",
    "\n",
    "\n",
    "\n",
    "# Question:\n",
    "# {question}\n",
    "# \"\"\"\n",
    "\n",
    "#         response = self.client.chat.completions.create(\n",
    "#             model=\"databricks-meta-llama-3-1-8b-instruct\",\n",
    "#             messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#             temperature=0,\n",
    "#             max_tokens=300,\n",
    "#         )\n",
    "\n",
    "#         return response.choices[0].message.content.strip()\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # SQL EXECUTION\n",
    "#     # -----------------------------\n",
    "#     def run_sql(self, query: str) -> pd.DataFrame:\n",
    "#         with sql.connect(\n",
    "#         server_hostname=\"dbc-741c7540-6155.cloud.databricks.com\",\n",
    "#         http_path=\"/sql/1.0/warehouses/e2eb5bcf69add002\",\n",
    "#         access_token=os.environ[\"DATABRICKS_TOKEN\"],\n",
    "#                 ) as connection:\n",
    "#             return pd.read_sql(query, connection)\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # VECTOR SEARCH RETRIEVAL\n",
    "#     # -----------------------------\n",
    "#     def retrieve_context(self, question: str):\n",
    "#         docs = self.ingredient_summary_vs.similarity_search(question, k=3)\n",
    "#         if not docs:\n",
    "#             docs = self.pizza_vs.similarity_search(question, k=3)\n",
    "#         return docs\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # MAIN PREDICT\n",
    "#     # -----------------------------\n",
    "#     def predict(self, context, model_input):\n",
    "#         if isinstance(model_input, pd.DataFrame):\n",
    "#             question = model_input[\"query\"].iloc[0]\n",
    "#         else:\n",
    "#             question = model_input[\"query\"]\n",
    "\n",
    "#         question = str(question)\n",
    "#         intent = self.detect_query_intent(question)\n",
    "\n",
    "#         # ---------- SQL ROUTE ----------\n",
    "#         # if intent == \"SQL_ANALYTICS\":\n",
    "#         #     sql = self.generate_sql(question)\n",
    "#         #     result_df = self.run_sql(sql)\n",
    "\n",
    "#         #     return [{\n",
    "#         #                 \"answer\": result_df.to_json(orient=\"records\"),\n",
    "#         #                 \"intent\": \"SQL_ANALYTICS\",\n",
    "#         #                 \"sql\": sql,\n",
    "#         #                 \"num_rows\": len(result_df),\n",
    "#         #                 \"num_documents\": 0,\n",
    "#         #             }]\n",
    "#         if intent == \"SQL_ANALYTICS\":\n",
    "#             sql_query = self.generate_sql(question)\n",
    "#             result_df = self.run_sql(sql_query)\n",
    "#             if result_df.empty:\n",
    "#                     return [{\n",
    "#                     \"answer\": \"No data found for the given question.\",\n",
    "#                     \"intent\": \"SQL_ANALYTICS\",\n",
    "#                     \"sql\": sql_query,\n",
    "#                     \"num_rows\": 0,\n",
    "#                     \"num_documents\": 0,\n",
    "#                             }]\n",
    "#             rows_json = result_df.to_json(orient=\"records\")\n",
    "\n",
    "#             # ---------- LLM EXPLANATION ----------\n",
    "#             explanation_prompt = f\"\"\"\n",
    "# You are a business analyst.\n",
    "\n",
    "# User question:\n",
    "# {question}\n",
    "\n",
    "# SQL query executed:\n",
    "# {sql_query}\n",
    "\n",
    "# SQL result (JSON):\n",
    "# {rows_json}\n",
    "\n",
    "# Explain the answer clearly and concisely in plain English.\n",
    "# If numbers are present, compute totals accurately.\n",
    "# Do NOT mention SQL or JSON in the final answer.\n",
    "# Do NOT add assumptions\n",
    "# \"\"\"\n",
    "\n",
    "#             explanation = self.client.chat.completions.create(\n",
    "#                 # model=\"databricks-meta-llama-3-1-8b-instruct\",\n",
    "#                 model=\"databricks-gpt-oss-120b\",\n",
    "#                 messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"You explain SQL results accurately.\"},\n",
    "#             {\"role\": \"user\", \"content\": explanation_prompt},\n",
    "#                     ],\n",
    "#                 temperature=0.1,\n",
    "#                 max_tokens=200,\n",
    "#             )\n",
    "\n",
    "#             return [{\n",
    "#                 \"answer\": explanation.choices[0].message.content,  # human-readable\n",
    "#                 \"intent\": \"SQL_ANALYTICS\",\n",
    "#                 \"sql\": sql_query,                                  # traceability\n",
    "#                 \"num_rows\": len(result_df),\n",
    "#                 \"num_documents\": 0,\n",
    "#                      }]\n",
    "\n",
    "\n",
    "#         # ---------- RAG ROUTE ----------\n",
    "#         docs = self.retrieve_context(question)\n",
    "\n",
    "#         if not docs:\n",
    "#             return [{\n",
    "#                 \"answer\": \"No relevant information found.\",\n",
    "#                 \"intent\": \"SEMANTIC\",\n",
    "#                 \"num_documents\": 0,\n",
    "#             }]\n",
    "\n",
    "#         context_text = \"\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "#         response = self.client.chat.completions.create(\n",
    "#             model=\"databricks-gpt-oss-120b\",\n",
    "#             messages=[\n",
    "#                 {\n",
    "#                     \"role\": \"system\",\n",
    "#                     \"content\": \"Answer ONLY using provided context.\"\n",
    "#                 },\n",
    "#                 {\n",
    "#                     \"role\": \"user\",\n",
    "#                     \"content\": context_text + \"\\n\\n\" + question\n",
    "#                 }\n",
    "#             ],\n",
    "#             temperature=0.3,\n",
    "#             max_tokens=400,\n",
    "#         )\n",
    "\n",
    "#         return [{\n",
    "#                 \"answer\": response.choices[0].message.content,\n",
    "#                 \"intent\": \"SEMANTIC\",\n",
    "#                 \"sql\": \"\",\n",
    "#                 \"num_rows\": 0,\n",
    "#                 \"num_documents\": len(docs),\n",
    "#                 }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2cebfc9-b91c-48fc-a13e-49b6250cd4c9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "sql orchestrated code"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import mlflow.pyfunc\n",
    "# from openai import OpenAI\n",
    "# from databricks import sql\n",
    "# from databricks_langchain import DatabricksVectorSearch\n",
    "\n",
    "\n",
    "# class PizzaRAGPyFuncModel(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "#     # ------------------------------------------------------------------\n",
    "#     # LOAD CONTEXT\n",
    "#     # ------------------------------------------------------------------\n",
    "#     def load_context(self, context):\n",
    "\n",
    "#         self.client = OpenAI(\n",
    "#             base_url=f\"{os.environ['DATABRICKS_HOST']}/serving-endpoints\",\n",
    "#             api_key=os.environ[\"DATABRICKS_TOKEN\"],\n",
    "#         )\n",
    "\n",
    "#         self.ingredient_summary_vs = DatabricksVectorSearch(\n",
    "#             index_name=\"retail_analytics.pizza.gold_semantic_ingredient_summary_index\",\n",
    "#             endpoint=\"pizza-rag-endpoint\",\n",
    "#         )\n",
    "\n",
    "#         self.pizza_vs = DatabricksVectorSearch(\n",
    "#             index_name=\"retail_analytics.pizza.gold_semantic_pizza_index\",\n",
    "#             endpoint=\"pizza-rag-endpoint\",\n",
    "#         )\n",
    "\n",
    "#     # ------------------------------------------------------------------\n",
    "#     # STEP 1: QUERY PLANNER (LLM, JSON ONLY)\n",
    "#     # ------------------------------------------------------------------\n",
    "    \n",
    "#     def plan_query(self, question: str) -> dict:\n",
    "#         prompt = f\"\"\"\n",
    "# Return ONLY valid JSON. No text. No markdown.\n",
    "\n",
    "# Schema:\n",
    "# {{\n",
    "#   \"domain\": \"SALES | INGREDIENT | SEMANTIC\",\n",
    "#   \"time_granularity\": \"DAILY | MONTHLY | NONE\",\n",
    "#   \"metric\": \"REVENUE | SALES | INGREDIENT_USAGE | NONE\",\n",
    "#   \"aggregation\": \"SUM | MAX | MIN | AVG | NONE\",\n",
    "#   \"filters\": {{\n",
    "#     \"year\": null,\n",
    "#     \"month\": null,\n",
    "#     \"day\": null\n",
    "#   }}\n",
    "# }}\n",
    "\n",
    "# Question:\n",
    "# {question}\n",
    "# \"\"\"\n",
    "\n",
    "#         try:\n",
    "#             response = self.client.chat.completions.create(\n",
    "#                 model=\"databricks-meta-llama-3-1-8b-instruct\",\n",
    "#                 messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#                 temperature=0,\n",
    "#                 max_tokens=200,\n",
    "#             )\n",
    "\n",
    "#             raw = response.choices[0].message.content.strip()\n",
    "\n",
    "#         # ---- HARD CLEANING ----\n",
    "#             raw = raw.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "#             plan = json.loads(raw)\n",
    "\n",
    "#         # ---- SCHEMA GUARD ----\n",
    "#             required_keys = {\"domain\", \"time_granularity\", \"metric\", \"aggregation\", \"filters\"}\n",
    "#             if not required_keys.issubset(plan):\n",
    "#                 raise ValueError(\"Invalid plan schema\")\n",
    "\n",
    "#             return plan\n",
    "\n",
    "#         except Exception as e:\n",
    "#         # ---- SAFE FALLBACK (CRITICAL) ----\n",
    "#             return {\n",
    "#             \"domain\": \"SEMANTIC\",\n",
    "#             \"time_granularity\": \"NONE\",\n",
    "#             \"metric\": \"NONE\",\n",
    "#             \"aggregation\": \"NONE\",\n",
    "#             \"filters\": {\n",
    "#                 \"year\": None,\n",
    "#                 \"month\": None,\n",
    "#                 \"day\": None\n",
    "#                 }\n",
    "#             }\n",
    "\n",
    "\n",
    "\n",
    "#     # ------------------------------------------------------------------\n",
    "#     # STEP 2: ROUTE TABLE & COLUMNS (NO LLM)\n",
    "#     # ------------------------------------------------------------------\n",
    "#     def resolve_sql_plan(self, plan: dict) -> dict:\n",
    "\n",
    "#         if plan[\"domain\"] == \"INGREDIENT\":\n",
    "#             return {\n",
    "#                 \"table\": \"retail_analytics.pizza.gold_ingredient_usage\",\n",
    "#                 \"metric_column\": \"total_ingredient_grams\",\n",
    "#             }\n",
    "\n",
    "#         if plan[\"time_granularity\"] == \"DAILY\":\n",
    "#             return {\n",
    "#                 \"table\": \"retail_analytics.pizza.gold_pizza_metrics_daily\",\n",
    "#                 \"metric_column\": \"revenue_perday\",\n",
    "#             }\n",
    "\n",
    "#         if plan[\"time_granularity\"] == \"MONTHLY\":\n",
    "#             return {\n",
    "#                 \"table\": \"retail_analytics.pizza.gold_pizza_metrics_monthly\",\n",
    "#                 \"metric_column\": \"total_revenue\"\n",
    "#                 if plan[\"metric\"] == \"REVENUE\"\n",
    "#                 else \"total_pizzas_sold\",\n",
    "#             }\n",
    "\n",
    "#         return {}\n",
    "\n",
    "#     # ------------------------------------------------------------------\n",
    "#     # STEP 3: SAFE SQL BUILDER (CODE, NOT LLM)\n",
    "#     # ------------------------------------------------------------------\n",
    "#     def build_sql(self, plan: dict, sql_meta: dict) -> str:\n",
    "\n",
    "#         metric = sql_meta[\"metric_column\"]\n",
    "#         table = sql_meta[\"table\"]\n",
    "#         agg = plan[\"aggregation\"]\n",
    "\n",
    "#         where = []\n",
    "#         for k, v in plan[\"filters\"].items():\n",
    "#             if v is not None:\n",
    "#                 where.append(f\"{k} = {v}\")\n",
    "\n",
    "#         where_clause = f\"WHERE {' AND '.join(where)}\" if where else \"\"\n",
    "\n",
    "#         return f\"\"\"\n",
    "# SELECT\n",
    "#   {agg}({metric}) AS value\n",
    "# FROM\n",
    "#   {table}\n",
    "# {where_clause}\n",
    "# \"\"\".strip()\n",
    "\n",
    "#     # ------------------------------------------------------------------\n",
    "#     # STEP 4: SQL EXECUTION\n",
    "#     # ------------------------------------------------------------------\n",
    "#     def run_sql(self, query: str) -> pd.DataFrame:\n",
    "#         with sql.connect(\n",
    "#             server_hostname=\"dbc-741c7540-6155.cloud.databricks.com\",\n",
    "#             http_path=\"/sql/1.0/warehouses/e2eb5bcf69add002\",\n",
    "#             access_token=os.environ[\"DATABRICKS_TOKEN\"],\n",
    "#         ) as conn:\n",
    "#             return pd.read_sql(query, conn)\n",
    "\n",
    "#     # ------------------------------------------------------------------\n",
    "#     # STEP 5: EXPLAIN RESULTS (LLM)\n",
    "#     # ------------------------------------------------------------------\n",
    "#     def explain_result(self, question: str, result_df: pd.DataFrame) -> str:\n",
    "#         prompt = f\"\"\"\n",
    "# Explain the result in simple business language.\n",
    "\n",
    "# Question:\n",
    "# {question}\n",
    "\n",
    "# Result:\n",
    "# {result_df.to_dict(orient=\"records\")}\n",
    "\n",
    "# Do NOT mention SQL.\n",
    "# \"\"\"\n",
    "\n",
    "#         response = self.client.chat.completions.create(\n",
    "#             model=\"databricks-gpt-oss-120b\",\n",
    "#             messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#             temperature=0.1,\n",
    "#             max_tokens=150,\n",
    "#         )\n",
    "\n",
    "#         return response.choices[0].message.content\n",
    "\n",
    "#     # ------------------------------------------------------------------\n",
    "#     # MAIN PREDICT\n",
    "#     # ------------------------------------------------------------------\n",
    "#     def predict(self, context, model_input):\n",
    "\n",
    "#         question = (\n",
    "#             model_input[\"query\"].iloc[0]\n",
    "#             if isinstance(model_input, pd.DataFrame)\n",
    "#             else model_input[\"query\"]\n",
    "#         )\n",
    "\n",
    "#         # 1️⃣ Plan\n",
    "#         plan = self.plan_query(question)\n",
    "\n",
    "#         # 2️⃣ Semantic-only route\n",
    "#         if plan[\"domain\"] == \"SEMANTIC\":\n",
    "#             docs = self.ingredient_summary_vs.similarity_search(question, k=3)\n",
    "#             context_text = \"\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "#             response = self.client.chat.completions.create(\n",
    "#                 model=\"databricks-gpt-oss-120b\",\n",
    "#                 messages=[\n",
    "#                     {\"role\": \"system\", \"content\": \"Answer using context only\"},\n",
    "#                     {\"role\": \"user\", \"content\": context_text + \"\\n\\n\" + question},\n",
    "#                 ],\n",
    "#                 temperature=0.3,\n",
    "#                 max_tokens=300,\n",
    "#             )\n",
    "\n",
    "#             return [{\n",
    "#                 \"answer\": response.choices[0].message.content,\n",
    "#                 \"intent\": \"SEMANTIC\",\n",
    "#                 \"sql\": \"\",\n",
    "#                 \"num_rows\": 0,\n",
    "#                 \"num_documents\": len(docs),\n",
    "#             }]\n",
    "\n",
    "#         # 3️⃣ SQL route\n",
    "#         sql_meta = self.resolve_sql_plan(plan)\n",
    "#         sql_query = self.build_sql(plan, sql_meta)\n",
    "#         df = self.run_sql(sql_query)\n",
    "\n",
    "#         if df.empty:\n",
    "#             return [{\n",
    "#                 \"answer\": \"No data found for the given question.\",\n",
    "#                 \"intent\": \"SQL_ANALYTICS\",\n",
    "#                 \"sql\": sql_query,\n",
    "#                 \"num_rows\": 0,\n",
    "#                 \"num_documents\": 0,\n",
    "#             }]\n",
    "\n",
    "#         explanation = self.explain_result(question, df)\n",
    "\n",
    "#         return [{\n",
    "#             \"answer\": explanation,\n",
    "#             \"intent\": \"SQL_ANALYTICS\",\n",
    "#             \"sql\": sql_query,\n",
    "#             \"num_rows\": len(df),\n",
    "#             \"num_documents\": 0,\n",
    "#         }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba1096db-1522-447b-b467-1628ca3f634a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "sql orchestration with question detecter"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import mlflow.pyfunc\n",
    "from openai import OpenAI\n",
    "from databricks import sql\n",
    "from databricks_langchain import DatabricksVectorSearch\n",
    "\n",
    "\n",
    "class PizzaRAGPyFuncModel(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    # ==========================================================\n",
    "    # LOAD CONTEXT\n",
    "    # ==========================================================\n",
    "    def load_context(self, context):\n",
    "\n",
    "        self.client = OpenAI(\n",
    "            base_url=f\"{os.environ['DATABRICKS_HOST']}/serving-endpoints\",\n",
    "            api_key=os.environ[\"DATABRICKS_TOKEN\"],\n",
    "        )\n",
    "\n",
    "        self.ingredient_summary_vs = DatabricksVectorSearch(\n",
    "            index_name=\"retail_analytics.pizza.gold_semantic_ingredient_summary_index\",\n",
    "            endpoint=\"pizza-rag-endpoint\",\n",
    "        )\n",
    "\n",
    "        self.pizza_vs = DatabricksVectorSearch(\n",
    "            index_name=\"retail_analytics.pizza.gold_semantic_pizza_index\",\n",
    "            endpoint=\"pizza-rag-endpoint\",\n",
    "        )\n",
    "\n",
    "    # ==========================================================\n",
    "    # STEP 1 — QUERY PLANNER (LLM → STRICT JSON)\n",
    "    # ==========================================================\n",
    "    def plan_query(self, question: str) -> dict:\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "Return ONLY valid JSON. No markdown. No explanation.\n",
    "\n",
    "Schema:\n",
    "{{\n",
    "  \"domain\": \"SALES | INGREDIENT | SEMANTIC\",\n",
    "  \"time_granularity\": \"DAILY | MONTHLY | NONE\",\n",
    "  \"metric\": \"REVENUE | SALES | INGREDIENT_USAGE | NONE\",\n",
    "  \"aggregation\": \"SUM | MAX | MIN | AVG | NONE\",\n",
    "  \"filters\": {{\n",
    "    \"year\": null,\n",
    "    \"month\": null,\n",
    "    \"day\": null\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"databricks-meta-llama-3-1-8b-instruct\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0,\n",
    "                max_tokens=200,\n",
    "            )\n",
    "\n",
    "            raw = response.choices[0].message.content.strip()\n",
    "            raw = raw.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            plan = json.loads(raw)\n",
    "\n",
    "            required = {\"domain\", \"time_granularity\", \"metric\", \"aggregation\", \"filters\"}\n",
    "            if not required.issubset(plan):\n",
    "                raise ValueError(\"Invalid planner output\")\n",
    "\n",
    "            return plan\n",
    "\n",
    "        except Exception:\n",
    "            # HARD FAILSAFE\n",
    "            return {\n",
    "                \"domain\": \"SEMANTIC\",\n",
    "                \"time_granularity\": \"NONE\",\n",
    "                \"metric\": \"NONE\",\n",
    "                \"aggregation\": \"NONE\",\n",
    "                \"filters\": {\"year\": None, \"month\": None, \"day\": None},\n",
    "            }\n",
    "\n",
    "    # ==========================================================\n",
    "    # STEP 2 — ENTITY QUESTION DETECTOR (CODE)\n",
    "    # ==========================================================\n",
    "    # def is_entity_question(self, question: str) -> bool:\n",
    "    #     q = question.lower()\n",
    "    #     return any(k in q for k in [\"which\", \"what\", \"most\", \"highest\", \"top\",\"least\",\"lowest\"])\n",
    "    def parse_entity_intent(self, question: str) -> dict:\n",
    "        q = question.lower()\n",
    "\n",
    "        return {\n",
    "            \"is_entity\": any(k in q for k in [\"which\", \"what\", \"top\", \"most\", \"highest\", \"lowest\"]),\n",
    "            \"ranking\": (\n",
    "                \"MAX\" if any(k in q for k in [\"most\", \"highest\", \"max\"]) else\n",
    "                \"MIN\" if any(k in q for k in [\"least\", \"lowest\", \"min\"]) else\n",
    "                None\n",
    "            ),\n",
    "            \"top_k\": (\n",
    "                int(next((w for w in q.split() if w.isdigit()), \"1\"))\n",
    "            ),\n",
    "            \"needs_window\": any(k in q for k in [\n",
    "                \"per month\", \"per year\", \"each month\", \"each year\", \"trend\", \"rank\"\n",
    "            ])\n",
    "        }\n",
    "\n",
    "\n",
    "    # def needs_join(self, question: str) -> bool:\n",
    "    # q = question.lower()\n",
    "    # return (\n",
    "    #     \"ingredient\" in q\n",
    "    #     and any(k in q for k in [\"revenue\", \"sales\"])\n",
    "    # )\n",
    "    def resolve_joins(self, plan: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Decides base table and required joins.\n",
    "        \"\"\"\n",
    "\n",
    "        joins = []\n",
    "\n",
    "        # -------------------------------\n",
    "        # BASE TABLE\n",
    "        # -------------------------------\n",
    "        if plan[\"domain\"] == \"INGREDIENT\":\n",
    "            base_table = \"retail_analytics.pizza.gold_ingredient_usage\"\n",
    "            base_alias = \"i\"\n",
    "        elif plan[\"time_granularity\"] == \"DAILY\":\n",
    "            base_table = \"retail_analytics.pizza.gold_pizza_metrics_daily\"\n",
    "            base_alias = \"d\"\n",
    "        else:\n",
    "            base_table = \"retail_analytics.pizza.gold_pizza_metrics_monthly\"\n",
    "            base_alias = \"m\"\n",
    "\n",
    "        # -------------------------------\n",
    "        # INGREDIENT → SALES/REVENUE\n",
    "        # -------------------------------\n",
    "        if plan[\"domain\"] == \"INGREDIENT\" and plan[\"metric\"] in [\"REVENUE\", \"SALES\"]:\n",
    "            joins.append({\n",
    "                \"table\": \"retail_analytics.pizza.gold_pizza_metrics_monthly\",\n",
    "                \"alias\": \"m\",\n",
    "                \"on\": \"i.pizza_name_id = m.pizza_name_id AND i.month = m.month AND i.year = m.year\"\n",
    "            })\n",
    "\n",
    "        # -------------------------------\n",
    "        # DAILY → MONTHLY (rollups)\n",
    "        # -------------------------------\n",
    "        if plan[\"time_granularity\"] == \"DAILY\" and plan[\"metric\"] == \"REVENUE\":\n",
    "            joins.append({\n",
    "                \"table\": \"retail_analytics.pizza.gold_pizza_metrics_monthly\",\n",
    "                \"alias\": \"m\",\n",
    "                \"on\": \"d.pizza_name_id = m.pizza_name_id AND d.month = m.month AND d.year = m.year\"\n",
    "            })\n",
    "\n",
    "        # -------------------------------\n",
    "        # INGREDIENT + DAILY + MONTHLY\n",
    "        # -------------------------------\n",
    "        if (\n",
    "            plan[\"domain\"] == \"INGREDIENT\"\n",
    "            and plan[\"time_granularity\"] == \"DAILY\"\n",
    "            and plan[\"metric\"] == \"REVENUE\"\n",
    "        ):\n",
    "            joins.append({\n",
    "                \"table\": \"retail_analytics.pizza.gold_pizza_metrics_daily\",\n",
    "                \"alias\": \"d\",\n",
    "                \"on\": \"i.pizza_name_id = d.pizza_name_id AND i.day = d.day AND i.month = d.month AND i.year = d.year\"\n",
    "            })\n",
    "            joins.append({\n",
    "                \"table\": \"retail_analytics.pizza.gold_pizza_metrics_monthly\",\n",
    "                \"alias\": \"m\",\n",
    "                \"on\": \"d.pizza_name_id = m.pizza_name_id AND d.month = m.month AND d.year = m.year\"\n",
    "            })\n",
    "\n",
    "        return {\n",
    "            \"base_table\": base_table,\n",
    "            \"base_alias\": base_alias,\n",
    "            \"joins\": joins\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    # ==========================================================\n",
    "    # STEP 3 — SQL PLAN RESOLUTION (NO LLM)\n",
    "    # ==========================================================\n",
    "    def resolve_sql_plan(self, plan: dict) -> dict:\n",
    "\n",
    "        if plan[\"domain\"] == \"INGREDIENT\":\n",
    "            return {\n",
    "                \"table\": \"retail_analytics.pizza.gold_ingredient_usage\",\n",
    "                \"metric_column\": \"total_ingredient_grams\",\n",
    "                \"entity_column\": \"ingredient\",\n",
    "            }\n",
    "\n",
    "        if plan[\"time_granularity\"] == \"DAILY\":\n",
    "            return {\n",
    "                \"table\": \"retail_analytics.pizza.gold_pizza_metrics_daily\",\n",
    "                \"metric_column\": \"revenue_perday\",\n",
    "                \"entity_column\": \"pizza_name_id\",\n",
    "            }\n",
    "\n",
    "        if plan[\"time_granularity\"] == \"MONTHLY\":\n",
    "            return {\n",
    "                \"table\": \"retail_analytics.pizza.gold_pizza_metrics_monthly\",\n",
    "                \"metric_column\": \"total_revenue\"\n",
    "                if plan[\"metric\"] == \"REVENUE\"\n",
    "                else \"total_pizzas_sold\",\n",
    "                \"entity_column\": \"pizza_name_id\",\n",
    "            }\n",
    "\n",
    "        return {}\n",
    "\n",
    "    # ==========================================================\n",
    "    # STEP 4 — SAFE SQL BUILDER (DETERMINISTIC)\n",
    "    # ==========================================================\n",
    "\n",
    "    def build_sql(self, plan: dict, meta: dict, question: str) -> str:\n",
    "\n",
    "        entity_meta = self.parse_entity_intent(question)\n",
    "        join_plan = self.resolve_joins(plan)\n",
    "\n",
    "        base = join_plan[\"base_table\"]\n",
    "        b = join_plan[\"base_alias\"]\n",
    "        joins = join_plan[\"joins\"]\n",
    "\n",
    "        metric = meta[\"metric_column\"]\n",
    "        entity = meta.get(\"entity_column\")\n",
    "        agg = plan[\"aggregation\"]\n",
    "\n",
    "        # --------------------------------\n",
    "        # PARTITION LOGIC (WINDOW)\n",
    "        # --------------------------------\n",
    "        partition_cols = []\n",
    "        if plan[\"time_granularity\"] == \"MONTHLY\":\n",
    "            partition_cols = [\"year\", \"month\"]\n",
    "        elif plan[\"time_granularity\"] == \"DAILY\":\n",
    "            partition_cols = [\"year\", \"month\", \"day\"]\n",
    "\n",
    "        partition_sql = \", \".join(f\"{b}.{c}\" for c in partition_cols)\n",
    "\n",
    "        # --------------------------------\n",
    "        # WHERE\n",
    "        # --------------------------------\n",
    "        filters = []\n",
    "        for k, v in plan[\"filters\"].items():\n",
    "            if v is not None:\n",
    "                filters.append(f\"{b}.{k} = {v}\")\n",
    "\n",
    "        where_clause = f\"WHERE {' AND '.join(filters)}\" if filters else \"\"\n",
    "\n",
    "        # --------------------------------\n",
    "        # JOIN CLAUSE\n",
    "        # --------------------------------\n",
    "        join_sql = \"\\n\".join(\n",
    "            f\"JOIN {j['table']} {j['alias']} ON {j['on']}\"\n",
    "            for j in joins\n",
    "        )\n",
    "\n",
    "        # --------------------------------\n",
    "        # WINDOW FUNCTION QUERY\n",
    "        # --------------------------------\n",
    "        if entity_meta[\"needs_window\"] and entity:\n",
    "\n",
    "            order_dir = \"DESC\" if entity_meta[\"ranking\"] != \"MIN\" else \"ASC\"\n",
    "            limit_k = entity_meta[\"top_k\"]\n",
    "\n",
    "            return f\"\"\"\n",
    "WITH ranked_data AS (\n",
    "  SELECT\n",
    "    {b}.{entity},\n",
    "    {partition_sql},\n",
    "    {agg}({metric}) AS value,\n",
    "    RANK() OVER (\n",
    "      PARTITION BY {partition_sql}\n",
    "      ORDER BY {agg}({metric}) {order_dir}\n",
    "    ) AS rnk\n",
    "  FROM {base} {b}\n",
    "  {join_sql}\n",
    "  {where_clause}\n",
    "  GROUP BY {b}.{entity}, {partition_sql}\n",
    ")\n",
    "SELECT *\n",
    "FROM ranked_data\n",
    "WHERE rnk <= {limit_k}\n",
    "ORDER BY {partition_sql}, rnk\n",
    "\"\"\".strip()\n",
    "\n",
    "    # --------------------------------\n",
    "    # ENTITY (NO WINDOW)\n",
    "    # --------------------------------\n",
    "        if entity_meta[\"is_entity\"] and entity:\n",
    "            order_dir = \"DESC\" if entity_meta[\"ranking\"] != \"MIN\" else \"ASC\"\n",
    "            limit_k = entity_meta[\"top_k\"]\n",
    "\n",
    "            return f\"\"\"\n",
    "SELECT\n",
    "  {b}.{entity},\n",
    "  {agg}({metric}) AS value\n",
    "FROM {base} {b}\n",
    "{join_sql}\n",
    "{where_clause}\n",
    "GROUP BY {b}.{entity}\n",
    "ORDER BY value {order_dir}\n",
    "LIMIT {limit_k}\n",
    "\"\"\".strip()\n",
    "\n",
    "    # --------------------------------\n",
    "    # METRIC ONLY\n",
    "    # --------------------------------\n",
    "        return f\"\"\"\n",
    "SELECT\n",
    "  {agg}({metric}) AS value\n",
    "FROM {base} {b}\n",
    "{join_sql}\n",
    "{where_clause}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "    # ==========================================================\n",
    "    # STEP 5 — SQL EXECUTION\n",
    "    # ==========================================================\n",
    "    def run_sql(self, query: str) -> pd.DataFrame:\n",
    "        with sql.connect(\n",
    "            server_hostname=\"dbc-741c7540-6155.cloud.databricks.com\",\n",
    "            http_path=\"/sql/1.0/warehouses/e2eb5bcf69add002\",\n",
    "            access_token=os.environ[\"DATABRICKS_TOKEN\"],\n",
    "        ) as conn:\n",
    "            return pd.read_sql(query, conn)\n",
    "\n",
    "    # ==========================================================\n",
    "    # STEP 6 — RESULT EXPLANATION (LLM)\n",
    "    # ==========================================================\n",
    "    def explain_result(self, question: str, df: pd.DataFrame) -> str:\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "Explain the result in clear business language.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Result:\n",
    "{df.to_dict(orient=\"records\")}\n",
    "\n",
    "Rules:\n",
    "- Do NOT mention SQL\n",
    "- Do NOT mention JSON\n",
    "- Do NOT add assumptions\n",
    "\"\"\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"databricks-gpt-oss-120b\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1,\n",
    "            max_tokens=150,\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    # ==========================================================\n",
    "    # MAIN PREDICT\n",
    "    # ==========================================================\n",
    "    def predict(self, context, model_input):\n",
    "\n",
    "        question = (\n",
    "            model_input[\"query\"].iloc[0]\n",
    "            if isinstance(model_input, pd.DataFrame)\n",
    "            else model_input[\"query\"]\n",
    "        )\n",
    "\n",
    "        # 1️⃣ PLAN\n",
    "        plan = self.plan_query(question)\n",
    "\n",
    "        # 2️⃣ SEMANTIC ROUTE\n",
    "        if plan[\"domain\"] == \"SEMANTIC\":\n",
    "            docs = self.ingredient_summary_vs.similarity_search(question, k=3)\n",
    "            context_text = \"\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"databricks-gpt-oss-120b\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Answer using provided context only\"},\n",
    "                    {\"role\": \"user\", \"content\": context_text + \"\\n\\n\" + question},\n",
    "                ],\n",
    "                temperature=0.3,\n",
    "                max_tokens=300,\n",
    "            )\n",
    "\n",
    "            return [{\n",
    "                \"answer\": response.choices[0].message.content,\n",
    "                \"intent\": \"SEMANTIC\",\n",
    "                \"sql\": \"\",\n",
    "                \"num_rows\": 0,\n",
    "                \"num_documents\": len(docs),\n",
    "            }]\n",
    "\n",
    "        # 3️⃣ SQL ROUTE\n",
    "        meta = self.resolve_sql_plan(plan)\n",
    "        sql_query = self.build_sql(plan, meta, question)\n",
    "        df = self.run_sql(sql_query)\n",
    "\n",
    "        if df.empty:\n",
    "            return [{\n",
    "                \"answer\": \"No data found for the given question.\",\n",
    "                \"intent\": \"SQL_ANALYTICS\",\n",
    "                \"sql\": sql_query,\n",
    "                \"num_rows\": 0,\n",
    "                \"num_documents\": 0,\n",
    "            }]\n",
    "\n",
    "        explanation = self.explain_result(question, df)\n",
    "\n",
    "        return [{\n",
    "            \"answer\": explanation,\n",
    "            \"intent\": \"SQL_ANALYTICS\",\n",
    "            \"sql\": sql_query,\n",
    "            \"num_rows\": len(df),\n",
    "            \"num_documents\": 0,\n",
    "        }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7379e68-8ef8-4369-a9c0-5359742693c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import ModelSignature\n",
    "from mlflow.types import Schema, ColSpec\n",
    "\n",
    "signature = ModelSignature(\n",
    "    inputs=Schema([\n",
    "        ColSpec(\"string\", \"query\")\n",
    "    ]),\n",
    "    outputs=Schema([\n",
    "        ColSpec(\"string\", \"answer\"),\n",
    "        ColSpec(\"string\", \"intent\"),\n",
    "        ColSpec(\"string\", \"sql\"),\n",
    "        ColSpec(\"long\", \"num_rows\"),\n",
    "        ColSpec(\"long\", \"num_documents\"),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.log_model(\n",
    "        name=\"pizza_rag_model\",\n",
    "        python_model=PizzaRAGPyFuncModel(),\n",
    "        signature=signature,\n",
    "        input_example={\"query\": \"how much revenue generated in 25 december and year 2015\"},\n",
    "        registered_model_name=\"retail_analytics.pizza.pizza_rag_models\",\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "rag_application_prod",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
